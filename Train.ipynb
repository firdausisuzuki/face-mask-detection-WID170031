{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.19.3\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'c:\\users\\pc\\anaconda3\\lib\\site-packages')\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries and modules required.\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build convolution network consists of two pairs of Conv and MaxPool layers to extract features.\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(100, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1315 images belonging to 2 classes.\n",
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Data Generation and Augmentation.\n",
    "\n",
    "TRAINING_DIR = \"./train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))\n",
    "VALIDATION_DIR = \"./test\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a callback checkpoint to keep saving best model after each epoch while training.\n",
    "\n",
    "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 35s 259ms/step - loss: 0.7858 - acc: 0.5133 - val_loss: 0.6931 - val_acc: 0.4742\n",
      "INFO:tensorflow:Assets written to: model2-001.model\\assets\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 34s 256ms/step - loss: 0.6932 - acc: 0.5086 - val_loss: 0.6930 - val_acc: 0.5052\n",
      "INFO:tensorflow:Assets written to: model2-002.model\\assets\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 34s 257ms/step - loss: 0.6884 - acc: 0.5173 - val_loss: 0.3720 - val_acc: 0.8969\n",
      "INFO:tensorflow:Assets written to: model2-003.model\\assets\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 34s 256ms/step - loss: 0.4725 - acc: 0.8283 - val_loss: 0.1979 - val_acc: 0.9330\n",
      "INFO:tensorflow:Assets written to: model2-004.model\\assets\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 34s 258ms/step - loss: 0.3273 - acc: 0.8950 - val_loss: 0.1067 - val_acc: 0.9639\n",
      "INFO:tensorflow:Assets written to: model2-005.model\\assets\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 34s 256ms/step - loss: 0.2663 - acc: 0.9092 - val_loss: 0.1286 - val_acc: 0.9485\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 34s 259ms/step - loss: 0.2585 - acc: 0.9188 - val_loss: 0.0955 - val_acc: 0.9845\n",
      "INFO:tensorflow:Assets written to: model2-007.model\\assets\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 35s 269ms/step - loss: 0.2157 - acc: 0.9278 - val_loss: 0.0639 - val_acc: 0.9691\n",
      "INFO:tensorflow:Assets written to: model2-008.model\\assets\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 36s 269ms/step - loss: 0.2228 - acc: 0.9013 - val_loss: 0.2119 - val_acc: 0.9227\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 36s 273ms/step - loss: 0.2517 - acc: 0.9012 - val_loss: 0.0635 - val_acc: 0.9742\n",
      "INFO:tensorflow:Assets written to: model2-010.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Train the model with 10 epochs.\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
